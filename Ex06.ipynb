{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhlRAGkkc-Sh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import layers\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32v7IU9Pom1o"
      },
      "source": [
        "Essential info about tagged entities:\n",
        "```\n",
        "geo = Geographical Entity\n",
        "org = Organization\n",
        "per = Person\n",
        "gpe = Geopolitical Entity\n",
        "tim = Time indicator\n",
        "art = Artifact\n",
        "eve = Event\n",
        "nat = Natural Phenomenon\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBffZlAgocDh"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqqCE7zqolER"
      },
      "outputs": [],
      "source": [
        "data.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoHAg7KZo69w"
      },
      "outputs": [],
      "source": [
        "data = data.fillna(method=\"ffill\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DMO1sJ9o9zA"
      },
      "outputs": [],
      "source": [
        "data.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArBV7Hu7pHUI"
      },
      "outputs": [],
      "source": [
        "print(\"Unique words in corpus:\", data['Word'].nunique())\n",
        "print(\"Unique tags in corpus:\", data['Tag'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsdckyINwrCW"
      },
      "outputs": [],
      "source": [
        "words=list(data['Word'].unique())\n",
        "words.append(\"ENDPAD\")\n",
        "tags=list(data['Tag'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IMsJobwpLpY"
      },
      "outputs": [],
      "source": [
        "print(\"Unique tags are:\", tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qg_ixvHZ0kkc"
      },
      "outputs": [],
      "source": [
        "num_words = len(words)\n",
        "num_tags = len(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dex8DMLv1F2V"
      },
      "outputs": [],
      "source": [
        "num_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz2RCZB6xFdd"
      },
      "outputs": [],
      "source": [
        "class SentenceGetter(object):\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H7HPRmRxILt"
      },
      "outputs": [],
      "source": [
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg3I0kQgFmCQ"
      },
      "outputs": [],
      "source": [
        "len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0LpMQoJxLdP"
      },
      "outputs": [],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd1m9pn4xeke"
      },
      "outputs": [],
      "source": [
        "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NjwbR3JxjsO"
      },
      "outputs": [],
      "source": [
        "word2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2qVRvVuxsH-"
      },
      "outputs": [],
      "source": [
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxiZjIPvyrbu"
      },
      "outputs": [],
      "source": [
        "X1 = [[word2idx[w[0]] for w in s] for s in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIrDysBvytG-"
      },
      "outputs": [],
      "source": [
        "type(X1[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvW4Yg2fy2I2"
      },
      "outputs": [],
      "source": [
        "X1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXiZQT9oyn7e"
      },
      "outputs": [],
      "source": [
        "max_len = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeYbmbt_zfIp"
      },
      "source": [
        "# **pad_sequences example**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T52hHPfbznyl"
      },
      "outputs": [],
      "source": [
        "nums = [[1], [2, 3], [4, 5, 6]]\n",
        "sequence.pad_sequences(nums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM9JwHM92FTs"
      },
      "outputs": [],
      "source": [
        "nums = [[1], [2, 3], [4, 5, 6]]\n",
        "sequence.pad_sequences(nums,maxlen=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOn14Tb50NgO"
      },
      "outputs": [],
      "source": [
        "X = sequence.pad_sequences(maxlen=max_len,\n",
        "                  sequences=X1, padding=\"post\",\n",
        "                  value=num_words-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG-20fXZ0pU0"
      },
      "outputs": [],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPvWZB-61ghV"
      },
      "outputs": [],
      "source": [
        "y1 = [[tag2idx[w[2]] for w in s] for s in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wST3Nrkp1k3s"
      },
      "outputs": [],
      "source": [
        "y = sequence.pad_sequences(maxlen=max_len,\n",
        "                  sequences=y1,\n",
        "                  padding=\"post\",\n",
        "                  value=tag2idx[\"O\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t23QC8Yj2eTV"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaWPtQJ04V7T"
      },
      "outputs": [],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPDp3MNr4ZRs"
      },
      "outputs": [],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgIT1Dox5Uo1"
      },
      "outputs": [],
      "source": [
        "input_word = layers.Input(shape=(max_len,))\n",
        "embedding_layer = layers.Embedding(input_dim=num_words,output_dim=50,\n",
        "                                   input_length=max_len)(input_word)\n",
        "dropout = layers.SpatialDropout1D(0.1)(embedding_layer)\n",
        "bid_lstm = layers.Bidirectional(\n",
        "    layers.LSTM(units=100,return_sequences=True,\n",
        "                recurrent_dropout=0.1))(dropout)\n",
        "output = layers.TimeDistributed(\n",
        "    layers.Dense(num_tags,activation=\"softmax\"))(bid_lstm)               \n",
        "model = Model(input_word, output)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFYOj10v6-YU"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wADTzVii7jxb"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAgUMZ_X7oSM"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_test,y_test),\n",
        "    batch_size=32, \n",
        "    epochs=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtVPlygc85Sa"
      },
      "outputs": [],
      "source": [
        "metrics = pd.DataFrame(model.history.history)\n",
        "metrics.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHu3hPWQ9B_C"
      },
      "outputs": [],
      "source": [
        "metrics[['accuracy','val_accuracy']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwJ0H2tt9E4q"
      },
      "outputs": [],
      "source": [
        "metrics[['loss','val_loss']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXmdlsAI9UKj"
      },
      "outputs": [],
      "source": [
        "i = 20\n",
        "p = model.predict(np.array([X_test[i]]))\n",
        "p = np.argmax(p, axis=-1)\n",
        "y_true = y_test[i]\n",
        "print(\"{:15}{:5}\\t {}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(\"-\" *30)\n",
        "for w, true, pred in zip(X_test[i], y_true, p[0]):\n",
        "    print(\"{:15}{}\\t{}\".format(words[w-1], tags[true], tags[pred]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
